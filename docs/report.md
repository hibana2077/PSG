# Path-Stability Generalization (PSG) 實驗報告

**日期:** 2026年1月21日  
**專案:** PSG Framework Validation  

---

## 摘要

本報告總結了 Path-Stability Generalization (PSG) 框架的初步驗證結果。實驗旨在檢驗「訓練路徑複雜度」（特別是 Path Length, PL 與 Gradient Energy, GE）是否能解釋泛化差異，並測試透過「路徑正則化」主動改善泛化的可能性。結果顯示 **PL 與泛化差距 (Generalization Gap) 呈現顯著正相關**，且路徑正則化能有效縮短路徑並抑制過擬合傾向，初步證實了 PSG 框架的核心假設。

---

## 實驗 A：指標相關性 (Correlation)

**目的:** 在多樣化的超參數設定（學習率、優化器、權重衰減等）下，驗證 PL 與 GE 是否能預測 Generalization Gap。

**結果數據 (Exp A):**
*   **Path Length (PL) vs Generalization Gap:** `Spearman Correlation = 0.58` (顯著正相關)。這表明訓練路徑越長，模型越傾向於過擬合（Gap 變大）。
*   **Gradient Energy (GE) vs Generalization Gap:** `Spearman Correlation = 0.34`。GE 亦呈現正相關，但預測力略低於 PL。
*   **Weight Decay:** 與 Gap 呈現負相關 (`-0.44`)，符合傳統認知。

**結論:** PL 是一個具有潛力的泛化預測指標，其與 Gap 的相關性強於傳統的 GE 指標，支持了「短路徑隱含更好泛化」的理論假設。

---

## 實驗 B：路徑正則化干預 (Intervention)

**目的:** 測試能否透過懲罰路徑長度（Path Regularization, $\lambda$）來主動控制泛化差距。

**結果數據 (Exp B):**
*   **正則化強度 ($\lambda$) 與 PL:** 相關係數高達 `-0.94`。隨著 $\lambda$ 增加 (0.0 $\to$ 1.0)，PL 顯著下降 (8.90 $\to$ 4.54)。
*   **正則化強度 ($\lambda$) 與 Gap:** 相關係數約 `-0.94`。強正則化導致 Gap 數值下降（變得更負），這意味著訓練 Loss 的上升幅度大於測試 Loss 的上升幅度。
*   **Loss 動態:**
    *   $\lambda=0.0$: Train Loss ~0.083, Test Loss ~0.069, Gap ~-0.013
    *   $\lambda=1.0$: Train Loss ~0.109, Test Loss ~0.091, Gap ~-0.018
    *   **解讀:** 雖然正則化稍微增加了 Test Loss（欠擬合風險），但它更大幅度地增加了 Train Loss，有效地限制了模型「死記硬背」訓練數據的能力。

**結論:** 路徑正則化能成功且精確地控制路徑長度 (PL)。此干預手段證實了我們不僅能觀測路徑，還能通過演算法主動塑造路徑幾何，進而影響模型的泛化行為。

---

## 實驗 C：壓力測試 (Stress Test)

**目的:** 測試在極端條件下（標籤雜訊、數據量變化）指標的穩健性。

**結果數據 (Exp C):**
*   **Label Noise vs Gap:** 呈現負相關 (`-0.37`)。在 Two-Moons 數據集上，隨機標籤雜訊似乎破壞了訓練過程，導致模型難以有效擬合訓練集，而非典型的過擬合記憶化。
*   **PL 在高雜訊下的表現:** PL 與 Gap 的相關性減弱 (`-0.09`)。這暗示在高度非典型的訓練環境下（如大量錯誤標籤），單純的幾何路徑長度可能不足以完全捕捉泛化行為，可能需要結合 GE 或其他指標。

---

## 實驗 D：嚴格控制變因驗證 (Strict Control Test)

**目的:** 執行「一擊斃命」實驗，試圖在鎖定 **Train Loss** (訓練誤差) 與 **Endpoint** (模型最終權重) 的前提下，觀察是否能單獨透過改變路徑性質 (如 PL) 來影響泛化。這旨在排除「模型學得好不好」與「最後學到什麼」的干擾。

**結果數據 (Exp D):**
*   **路徑僵固性 (Path Rigidity):** 實驗結果顯示，在嚴格控制 Train Loss (誤差 < 0.005) 與 Endpoint 位置 (相對距離 < 2%) 的條件下，**Path Length (PL) 幾乎無法發生顯著變化**。
    *   在 5 個隨機種子中，滿足對齊條件的 Path-Regularized 模型，其 PL 與 Baseline 的差異均小於 10%。
    *   若強行增加正則化強度 ($\lambda > 0.1$) 以縮短 PL，Train Loss 便會顯著惡化，無法滿足對齊前提。
*   **泛化差距鎖定:** 在滿足上述對齊條件的組別中，**Generalization Gap 幾乎完全重疊**。
    *   例如 Seed 0: Baseline Gap = -0.144, PathReg Gap = -0.144.
    *   所有樣本的 Gap 差異均在實驗誤差範圍內。

**結論:**
實驗 D 給出了一個重要的**否定性結果 (Negative Result)**，揭示了 PL 與模型收斂狀態的強耦合：
1.  **不可獨立性:** 我們無法在不犧牲訓練品質 (Train Loss) 或改變收斂位置 (Endpoint) 的情況下，顯著地縮短訓練路徑。這意味著「達到特定優良解的軌跡」在幾何長度上是相對固定的。
2.  **修正理論視角:** PSG 先前觀測到的「PL 越短泛化越好 (Exp B)」，其背後機制可能是路徑正則化強迫模型收斂到了**另一個**性質不同（比如更平坦、更簡單）的解 (Endpoint)，而非在同一個解上改變了「走法」。泛化的改善來自於「去哪裡」，而「怎麼走」(PL) 則是去該處的必要代價。

---

## 總結與展望

1.  **指標有效性:** 在標準設定下，**Path Length (PL)** 確實與 Generalization Gap 高度相關 (Exp A)，是一個有效的監測指標。
2.  **機制釐清:** Exp D 的結果修正了我們對因果機制的理解。我們不能單純將 PL 視為一個獨立的調節旋鈕。**短路徑與好泛化是「共生」的**，它們共同描述了一種特定的解的性質。試圖強行縮短路徑而不改變解的位置是不可行的。
3.  **未來方向:**
    *   **放棄「路徑獨立性」假設:** 承認路徑與終點的耦合，轉而研究為何「短路徑的終點」通常具有更好的泛化性。
    *   **結合 Geometry:** 探討 PL 與 Loss Landscape 曲率（Hessian）的關係。
    *   **實際應用:** 雖然不能「控制路徑來保留原解」，但路徑正則化 (Path Reg) 仍然是一個有效的手段來**引導**模型找到泛化更好的（不同的）解。

---
*報告生成依據：`runs/` 目錄下的實驗數據與 `docs/idea.md` 之研究規劃。*
